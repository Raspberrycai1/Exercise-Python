2020-10-7

《Mastering OpenCV 4 third edition》唐灿 译 ISBN：9787111645771 第二章

# 使用SfM模块从运动中恢复结构

SfM：是恢复场景中相机的位置和稀疏几何的过程。

OpenCV 3.0+ 增加了一个sfm模块，有助于利用多张图像来执行端到端的SfM处理。

实现：使用SfM模块将场景重建为稀疏点云，并生成相机姿态。之后，使用OpenMVS（MVS）多视图立体视觉库来增加点云的密度，使点云变得更加稠密。

任何一组具有足够多重叠部分的照片都能用来3D重建。拍照的要求是：照片间既要有足够的移动，也要有明显的重叠，以允许进行明确的成对匹配。

代码文件：https://github.com/PacktPublishing/Mastering-OpenCV-4-Third-Edition 下载

## 2.2 SfM的核心概念

### 2.2.1 相机标定和对极几何

#### 内参矩阵K

焦距（fx，fy）和主点偏移（cx，cy）

#### 外参矩阵[R|t]

多个相机的成像平面不共面

#### 本征矩阵

![image-20201007201000868](C:\Users\MY\Documents\GitHub\cloudimg\对极几何.png)

两台相机之间，有一个严格的变换 [R|t]。如果想在相机L的坐标系中表示相机 R 中的点 $x_R$ ，可以表示为 $Rx_R+t$ 。如果采用交叉乘积 $t \times Rx_R$，我们将得到一个垂直于极线平面的向量。因此，遵循 $x_L \cdot \times Rx_R =0$ ，因为xL 位于极线平面上，点积为0。我们采用交叉乘积的偏斜对称形式，可以写出 $ x^T_L[t] \times Rx_R =0$，然后将其组合成单个矩阵 $x^T_L E_{x_R} = 0$，我们称 E 为**本质矩阵**（essential matrix）。本质矩阵给出了相机L 和 相机R 之间真实3D 点上会聚的所有点对的**极线约束**。如果来自L和R的一对点无法满足此约束，则很可能不是有效配对。我们还可以使用多个点对来估计本质矩阵，因为他们可以构造成一个齐次线性方程组。该解可以通过特征值或**奇异值分解（SVD）**轻松获得。

#### 基本矩阵

假设相机被归一化，本质上意味着K=I，即单位矩阵。但是，在具有特定像素大小和焦距的真实图像中，必须考虑真实的内在因素。为此可以在两侧应用K的逆矩阵：
$$
(K^{-1}x_L)^T E K^{-1} x_R = x^T_L K^{-T} E K^{-1} x_R = x^T_L F x_R =0
$$
则最终得到的这个新矩阵称为**基本矩阵**（fundamental matrix），它可以从足够的像素坐标点配对中估计出来。如果我们知道K，就可以得到本质矩阵；然而，基本矩阵本身可以用作良好的极线约束。

### 2.2.2 立体重建和SfM

## 2.3 在OpenCV 中实现SfM

### 2.3.1 图像特征匹配

#### 1. 特征点检测

OpenCV提供了广泛的2D特征**检测器**（或称**提取器**）和**描述符**。

特征被设计为不受图像变换的影响，因此它们可以通过平移、旋转、缩放以及对场景物体的其他更复杂的变换（仿射、投影）来匹配。

OpenCV API 的最新成员之一是**AKAZE** 特征提取器和检测器，它在计算速度和转换的鲁棒性之间提供了非常好的折中。AKAZE的表现优于其他突出特征，例如ORB（Oriented BRIEF）和 SURF（Speeded Up Robust Features）。

AKAZE为每张图像计算AKAZE 特征，并将它们分别保存在keypoints 和 descriptions 数组中。（可省略转换为灰度图像一步，结果不会受影响）



#### 2. 特征点匹配

下一步是**匹配每对图像之间的特征** ：

OpenCV 提供了一个出色的特征匹配套件。AKAZE特征描述符是二进制字符串，意味着在匹配时它们不能被视为二进制编码的数值，它们必须使用逐位运算符进行位与位之间的比较。OpenCV位二进制特征匹配器提供了**海明距离**（Hamming distance）度量，其原理是计算两位序列之间不正确匹配的数量。

**比值检验**（ration test）与从图像B 中找出图像A 中的某个特征的单个匹配项不同，我们在图像B 中寻找两个匹配项，以确保没有混淆。如果两个潜在的特征匹配项太过相似（就它们的距离度量而言），无法判断哪个才是正确匹配，那么在匹配时可能会出现混淆。为了防止出现这种情况，我们选择把它们都抛弃。

#### 3. **互惠滤波器**

（reciprocity filter）。这个滤波器仅允许A到B 以及 B到A 的特征匹配（通过比值检验）。本质上，这是为了确保图像A、B之间特征的一对一对称匹配。互惠滤波器消除了更多的歧义，有助于更干净，更具鲁棒性的匹配：

#### 4. 最后，应用**对极约束**

（epipolar constraint）如果每两幅图像之间有一个有效的刚性变换，它们就会遵守特征点上的对极约束，即：$x^T_L F x_R = 0$，那些没有通过测试（足够成功）的图像很有可能不匹配，并且可能导致噪声。通过使用投票算法（RANSAC）计算基本矩阵并检查正确数据（inlier）和异常数据（outlier）的比值来实现这一点。我们使用一个阈值来丢弃达不到条件的匹配。

### 2.3.2 找到特征轨迹

特征轨迹：由单个场景中的特征点产生的2D 位置，穿过多个视图后，就形成了轨迹。

### 2.3.3 3D重建和可视化

原则上，在获得了轨迹后，需要将它们转换为OpenCV的sfm模块所期望的数据结构。不幸的是，sfm 模块缺乏好的文档说明，所以这部分我们必须通过阅读源代码来自行解决。

轨迹需要放置在多个单独的cv::Mat 的向量中，其中每个向量都包含一个对齐的cv：：Vec2d列表作为列，这意味着它有两行双精度数。我们还可推断出轨迹中缺失（不匹配）的特征点将具有负坐标。以下代码段将从匹配图中提取符合其数据结构的轨迹：

接下来运行重建函数，收集稀疏3D点云和对应的色彩，然后，将结果可视化（使用cv::viz::)：

`cv::sfm::reconstruct(tracks,Rs,Ts,K,points3d,true)`

这将产生带有点云和相机位置的稀疏重建。

### 2.3.4 用于稠密重建的MVS

























《深入理解OpenCV》华章科技 刘波 译 ISBN：9787111478188 第四章

# 使用OpenCV研究从运动中恢复结构

SfM : Structure from Motion 从运动中恢复结构。采用的方法：使用单目方法（monocular approach）；对一各离散且稀疏的视频帧几何，而不是连续的视频流（为了实现这样的限制，将使用Hartley和Zisserman在他们的成名著作《Mutiple View Geometry in Computer Vision》第9章至12章中的内容。

摄像机已经被标定好，其内部参数以矩阵K的形式存在。

## 从运动中恢复结构的基本概念

SfM算法的目的：大多数情况都想得到场景的几何形状，例如：物体在摄像机的什么位置以及他们的形状是什么。

## 从两幅图像估计摄像机的运行

## 重构场景

## 从视图中重构

## 重构细化

## 可视化三维点云

