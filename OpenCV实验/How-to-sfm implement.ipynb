{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [DMatch类](https://www.bbsmax.com/A/obzbr0x0zE/)\n",
    "\n",
    "1、2、3不用说，是三个构造函数。接着, \n",
    "\n",
    "**int queryIdx** –>是**测试图像**(图像2)的特征点描述符（descriptor）的下标，同时也是描述符对应特征点（keypoint)的下标。\n",
    "\n",
    "**int trainIdx** –> 是**样本图像**(图像1)的特征点描述符的下标，同样也是相应的特征点的下标。\n",
    "\n",
    "**int imgIdx** –>当样本是多张图像的话有用。\n",
    "\n",
    "**float distance** –>代表这一对匹配的特征点描述符（本质是向量）的**欧氏距离**，数值越小也就说明两个特征点越相像。\n",
    "\n",
    "最后， 也就是一个小于操作符的重载，用于比较和排序。 比较的是上述的distance，当然是越小越好。\n",
    "\n",
    "## [KeyPoints类](https://www.bbsmax.com/A/obzbr0x0zE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# AKAZE特征点检测和匹配\n",
    "def GetImageMatches(img1,img2):\n",
    "    #检测特征点并返回特征点keypoints 和特征点描述符descriptors\n",
    "    akaze = cv2.AKAZE_create()\n",
    "    kp1, desc1 = akaze.detectAndCompute(img1,None)\n",
    "    kp2, desc2 = akaze.detectAndCompute(img2,None)\n",
    "    \n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING,crossCheck = True)#crossCheck=True: 两个特征点之间距离须互为最近\n",
    "    matches = matcher.match(desc1, desc2)#返回最佳匹配特征点对matches(DMatch类)\n",
    "    \n",
    "    matches = sorted(matches, key = lambda x:x.distance)#按照距离将特征点对升序排列\n",
    "    #Dmatch.(float) distance 代表这一对匹配的特征点描述符（本质为向量）的欧式距离，数值越小说明两个特征点越像\n",
    "    \n",
    "    # 取前80%匹配对\n",
    "    good = []\n",
    "    #print(matches[int(len(matches)*0.8)])\n",
    "    for n in range (int(len(matches)*0.9)):\n",
    "        good.append(matches[n])\n",
    "    return kp1,desc1,kp2,desc2,good\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    img1 = cv2.imread(\"hat_L.jpg\")#检测到209个特征点，注意图片后缀\n",
    "    img2 = cv2.imread(\"hat_R.jpg\")#检测到532个特征点\n",
    "    kp1,desc1,kp2,desc2,matches = GetImageMatches(img1,img2)\n",
    "    \n",
    "    #显示keypoints\n",
    "    #必须要先初始化img2\n",
    "    img_ = img1.copy()\n",
    "    img_ = cv2.drawKeypoints(img1, kp1, img_, color=(0,255,0))\n",
    "    while cv2.waitKey(100) != 27:\n",
    "        cv2.imshow('Detected AKAZE keypoints', img_)\n",
    "    \n",
    "    #最后是连线可视化\n",
    "    res = cv2.drawMatches(img1, kp1, img2, kp2, matches[:], None, flags=2)\n",
    "    cv2.imshow('res',res)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到2个图像中匹配点的图像坐标\n",
    "def GetAlignedMatches(kp1,desc1,kp2,desc2,matches):\n",
    "    # 防止万一matches 列表还没排序：\n",
    "    matches = sorted(matches, key = lambda x:x.distance) #内建函数sorted按照元素的distance排序，返回一个新list\n",
    "    \n",
    "    # 从matches中取回两个图像的keypoints的对应的序号\n",
    "    img1idx = np.array([m.queryIdx for m in matches]) #图像2的特征点下标，将列表转换成ndarry（方便运算）\n",
    "    img2idx = np.array([m.trainIdx for m in matches]) #图像1的特征点下标\n",
    "    \n",
    "    # 取出匹配的keypoints（matches中元素数量 < 各自点集元素数量）\n",
    "    kp1_ = (np.array(kp1))[img1idx]\n",
    "    kp2_ = (np.array(kp2))[img2idx]\n",
    "    \n",
    "    # 取回匹配的keypoints的图像坐标\n",
    "    img1pts = np.array([kp.pt for kp in kp1_])\n",
    "    img2pts = np.array([kp.pt for kp in kp2_])\n",
    "    \n",
    "    return img1pts,img2pts,img1idx,img2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy.repeat 和 numpy.tile\n",
    "repeat 和 rile是属于ndarray对象的方法。\n",
    "\n",
    "**ndarray**\n",
    "1. ndarray.ndim：数组的维度，即数组轴（axes）的个数，其数量等于秩（rank）。\n",
    "2. ndarray.shape：各维度的大小\n",
    "\n",
    "**repeat**可以通过2个管道使用：(1)numpy.repeat(a,repeats,axis=None); (2)object(ndarray).repeat(repeats,axis=None)\n",
    "* axis = None，先行后列，逐个元素复制repeats次，形成一个行向量\n",
    "* axis=0,沿着y轴复制，实际上增加行数，列数不变，各行复制repeats次\n",
    "* axis=1,沿着x轴复制，实际上增加列数，行数不变，各列复制repeats次\n",
    "* repeats可以为一个数，也可以为一个矩阵，各元素代表每行/列复制几次（[2,3]意味着第一行/列重复2次，第二行/列重复3次，行/列由axis决定）\n",
    "\n",
    "**tile** 使用：numpy.tile(A,reps)重复数组A来构建新数组\n",
    "\n",
    "*A是待输入数组，reps 决定A沿着各个维度重复的次数。\n",
    "\n",
    "1. reps.ndim > A.ndim ：向A中添加新轴扩充A的维度。一般通过向shape对应的元组中添加1完成对A维度的扩充。扩充完成后,根据reps值对A中相应维度的值进行重复\n",
    "2. reps.ndim < A.ndim ：将reps扩充至与A相同的维度。也是向shape对应的元组的左侧添1：(3,),(1,3),(1,1,3)，然后再进行重复，重复整个矩阵。\n",
    "3. reps.ndim = A.ndim ：不需要扩充，直接按reps的值对相应维度的值进行重复"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy.linalg.svd 函数\n",
    "函数：np.linalg.svd(a,full_matrices=1,compute_uv=1)。\n",
    "* a 是一个形如（M,N）的矩阵\n",
    "* full_matrices 的取值是为0 或者 1，默认为1，这时U 的大小为（M，M），V的大小为（N，N）。如果full_matrices不是1，则u的大小为(M,K)，v的大小为(K,N) ，K=min(M,N)。\n",
    "\n",
    "返回值：u,s,v\n",
    "* u大小为(M,M)，s大小为(M,N)，v大小为(N,N)。\n",
    "* A = u*s*v\n",
    "* s是对矩阵a的**奇异值分解**。s除了对角元素不为0，其他元素都为0，并且对角元素从大到小排列。s中有n个奇异值，一般排在后面的比较接近0，所以仅保留比较大的r个奇异值。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由8点估算基本矩阵F\n",
    "def EstimateFundamentalMatrix(img1_8pts,img2_8pts):#输入两幅图像中的8个点\n",
    "    #如果不是就变成齐次坐标\n",
    "    if img1_8pts.shape[1] == 2: #如果图像每个特征点只有2个坐标\n",
    "        img1_8pts = cv2.convertPointsToHomogeneous(img1_8pts)[:,0,:]#变成齐次坐标：添1，在第二维增加一维，成为3维坐标，.shape = (141,1,3)\n",
    "        img2_8pts = cv2.convertPointsToHomogeneous(img2_8pts)[:,0,:]\n",
    "        #加[:,0,:]的作用是在第二维上减一维，变成：shape=(141,3)：加一个0减一维；如果0换成None，就是在该维度上加一维\n",
    "        \n",
    "    A = np.zeros((img1_8pts.shape[0],9)) #定义一个：图像1的第1维数(8) x 9 的全0矩阵A\n",
    "    \n",
    "    img1_8pts_ = img1_8pts.repeat(3,axis=1) #axis=1,各列复制3次（[111222333]），得到 img1pts_.shape=(8,9）\n",
    "    img2_8pts_ = np.tile(img2_8pts,(1,3)) #行方向不重复，列方向上矩阵重复3次[123 123 123]，得到 img2pts_.shape=(8,9)\n",
    "    \n",
    "    A = img1_8pts_ * img2_8pts_ #各元素对位相乘,A.shape=(8,9)\n",
    "    \n",
    "    u,s,v = np.linalg.svd(A) #线性代数.奇异值分解\n",
    "    F = v[-1,:].reshape((3,3),order='F') #取v的最后一行reshape，按优先列读写\n",
    "    \n",
    "    u,s,v = np.linalg.svd(F)\n",
    "    F = u.dot(np.diag(s).dot(v)) #矩阵内积\n",
    "    \n",
    "    F = F / F[-1,-1]\n",
    "    \n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test cell\n",
    "# data = mat([[1,2,3],[4,5,6]])\n",
    "img1_8pts= np.array([[397.51690674, 207.14871216, 1.], [345.48895264, 198.8712616 ,  1.        ],  [228.76841736, 244.31945801,  1.  ],  [346.37963867, 141.98188782,  1.        ], [359.28860474, 242.01344299,  1.        ],  [336.2354126 , 190.75994873,  1.        ], [251.89804077, 148.5166626 ,  1.        ],  [331.28744507, 239.37399292,  1.        ]])\n",
    "img2_8pts= np.array([[320.29403687, 164.46336365,  1. ],  [264.3164978 , 156.3860321, 1. ], [130.02644348, 137.49526978,   1.        ],  [268.4407959 ,  98.52967834,  1.        ],  [275.8727417 , 199.86174011,  1.        ],  [254.89256287, 148.70428467,  1.        ],  [169.9493866 , 105.59056854,  1. ],  [246.43341064 , 197.26600647,   1.        ]])\n",
    "\n",
    "A = np.zeros((img1_8pts.shape[0],9))\n",
    "\n",
    "img1_8pts_ = img1_8pts.repeat(3,axis=1)\n",
    "img2_8pts_ = np.tile(img2_8pts,(1,3))\n",
    "# print(img1_8pts_)\n",
    "# print(img2_8pts_)\n",
    "product = np.multiply(img1_8pts_, img2_8pts_)\n",
    "# a=array(([1,2,3],[4,5,6]))\n",
    "# b = array(([7,8,9],[10,11,12]))\n",
    "# c = a*b\n",
    "# print(a)\n",
    "# print(b)\n",
    "# print(c)\n",
    "# U,sigma,VT = np.linalg.svd(data)\n",
    "# print(U)\n",
    "# print(sigma)\n",
    "# print (VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算抽样误差\n",
    "def SampsonError(F,x1,x2):\n",
    "    num = np.sum(x1.dot(F) * x2, axis=-1) # 点集x1内积上F再与点集x2对位相乘，\n",
    "    \n",
    "    F_src = np.dot(F, x1.T)\n",
    "    Ft_dst = np.dot(F.T, x2.T)\n",
    "    \n",
    "    dst_F_src = np.sum(x2 * F_src.T, axis=1)\n",
    "    \n",
    "    return np.abs(dst_F_src)/np.sqrt(F_src[0]**2 + F_src[1]**2 + Ft_dst**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANSAC估计基本矩阵\n",
    "def EstimateFundamentalMatrixRANSAC(img1pts, img2pts, outlierThres, prob=None, iters=None):\n",
    "    if img1pts.shape[1]==2: #如果是2列，说明还不是齐次坐标，需要添加1\n",
    "        img1pts = cv2.convertPointsToHomogeneous(img1pts)[:,0,:]\n",
    "        img2pts = cv2.convertPointsToHomogeneous(img2pts)[:,0,:]\n",
    "    \n",
    "    bestInliers, bestF, bestmask = 0, None, None #定义最好的内点个数，最好的F，最好的组合\n",
    "    \n",
    "    for i in range(iters):\n",
    "        # 随机选8个点\n",
    "        mask = np.random.randint(low=0,high=img1pts.shape[0],size=(8,))\n",
    "        img1ptsiter = img1pts[mask]\n",
    "        img2ptsiter = img2pts[mask]\n",
    "#         print(\"img1ptsiter=\",img1ptsiter)\n",
    "#         print(\"img2ptsiter=\",img2ptsiter)\n",
    "        \n",
    "        # 估计基本矩阵，并评估误差\n",
    "        Fiter = EstimateFundamentalMatrix(img1ptsiter,img2ptsiter)\n",
    "        error = SampsonError(Fiter,img1pts,img2pts) \n",
    "        qualified = error < outlierThres #error小于outlierThres 的点为True\n",
    "        numInliers = np.sum(qualified) #统计True的个数\n",
    "        \n",
    "        # 更新最佳测量结果\n",
    "        if bestInliers < numInliers:\n",
    "            bestInliers = numInliers\n",
    "            bestF = Fiter\n",
    "            bestmask = mask #？？？？？？？？？？？\n",
    "            \n",
    "    # 拟合所有找到的内点上的最小二乘法\n",
    "    F = EstimateFundamentalMatrix(img1pts[bestmask], img2pts[bestmask])#???\n",
    "    \n",
    "    return F,bestmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用SVD方法将本质矩阵E分解为R 和 t\n",
    "def ExtractCameraPoses(E):\n",
    "    u,d,v = np.linalg.svd(E)\n",
    "    W = np.array(([0,-1,0], [1,0,0], [0,0,1]))\n",
    "    \n",
    "    Rs, Cs = np.zeros((4,3,3)), np.zeros((4,3))\n",
    "    \n",
    "    t = u[:,-1]\n",
    "    R1 = u.dot(W.dot(v))\n",
    "    R2 = u.dot(W.T.dot(v))\n",
    "    \n",
    "    if np.linalg.det(R1) < 0:\n",
    "        R1 = R1 * -1\n",
    "    \n",
    "    if np.linalg.det(R2) < 0:\n",
    "        R2 = R2 * -1\n",
    "        \n",
    "    return R1,R2,t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三角测量：直接线性方法（投影方程）\n",
    "def GetTriangulatedPts(img1pts,img2pts,K,R,t,triangulateFunc): \n",
    "    img1ptsHom = cv2.convertPointsToHomogeneous(img1pts)[:,0,:]\n",
    "    img2ptsHom = cv2.convertPointsToHomogeneous(img2pts)[:,0,:]\n",
    "\n",
    "    img1ptsNorm = (np.linalg.inv(K).dot(img1ptsHom.T)).T\n",
    "    img2ptsNorm = (np.linalg.inv(K).dot(img2ptsHom.T)).T\n",
    "\n",
    "    img1ptsNorm = cv2.convertPointsFromHomogeneous(img1ptsNorm)[:,0,:]\n",
    "    img2ptsNorm = cv2.convertPointsFromHomogeneous(img2ptsNorm)[:,0,:]\n",
    "    \n",
    "    pts4d = triangulateFunc(np.eye(3,4),np.hstack((R,t)),img1ptsNorm.T,img2ptsNorm.T)\n",
    "    pts3d = cv2.convertPointsFromHomogeneous(pts4d.T)[:,0,:]\n",
    "    \n",
    "    return pts3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把3D点坐标转换成meshlab适合的坐标\n",
    "def pts2ply(pts,filename = 'out.ply'):\n",
    "    f = open(filename,'w')\n",
    "    f.write('ply\\n')\n",
    "    f.write('format ascii 1.0\\n')\n",
    "    f.write('element vertex {}\\n'.format(pts.shape[0]))\n",
    "    \n",
    "    f.write('property float x\\n')\n",
    "    f.write('property float y\\n')\n",
    "    f.write('property float z\\n')\n",
    "    \n",
    "    f.write('property uchar red\\n')\n",
    "    f.write('property uchar green\\n')\n",
    "    f.write('property uchar blue\\n')\n",
    "    \n",
    "    f.write('end_header\\n')\n",
    "    \n",
    "    for pt in pts: \n",
    "        f.write('{} {} {} 255 255 255\\n'.format(pt[0],pt[1],pt[2]))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 主函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主函数\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#Reading two images for reference\n",
    "img1 = cv2.imread(\"hat_L.jpg\")#检测到258个特征点\n",
    "img2 = cv2.imread(\"hat_R.jpg\")#检测到284个特征点\n",
    "\n",
    "#Converting from BGR to RGB format\n",
    "img1 = img1[:,:,::-1]\n",
    "img2 = img2[:,:,::-1]\n",
    "\n",
    "# AKAZE特征点检测和匹配\n",
    "kp1,desc1,kp2,desc2,matches = GetImageMatches(img1,img2)\n",
    "# 对齐两个keypoints向量\n",
    "img1pts,img2pts,img1idx,img2idx = GetAlignedMatches(kp1,desc1,kp2,desc2,matches)\n",
    "\n",
    "# 计算基本矩阵——RANSAC\n",
    "F, mask = EstimateFundamentalMatrixRANSAC(img1pts,img2pts,0.1,iters=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.09010957  -6.33839553  -0.50945662]\n",
      " [  6.21103452   0.48415712  15.39172887]\n",
      " [  0.94337908 -16.24269927   0.89371002]]\n"
     ]
    }
   ],
   "source": [
    "# 由F求E\n",
    "K = np.array(([678.48, 0, 302.81], [0, 678.50, 225.80], [0, 0, 1]))\n",
    "#K = np.array(([681.12, 0, 303.78], [0, 680.58, 223.50], [0, 0, 1]))\n",
    "E = K.T.dot(F.dot(K))\n",
    "print(E)\n",
    "\n",
    "# 用SVD方法将本质矩阵E分解为R 和 t\n",
    "R1,R2,t = ExtractCameraPoses(E)\n",
    "t = t[:,np.newaxis]\n",
    "\n",
    "# 三角测量：直接线性方法（投影方程）得到特征点的三维坐标\n",
    "pts3d = GetTriangulatedPts(img1pts,img2pts,K,R2,t,cv2.triangulatePoints)\n",
    "\n",
    "# 把3D点坐标转换成meshlab适合的坐标\n",
    "pts2ply(pts3d,'castle_2view.ply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.85494340e+02 -2.70689699e+02  9.40935909e+01  7.20292706e+02]\n",
      " [-1.34061255e+02 -6.67792488e+02 -2.17781228e+02 -7.82865846e+01]\n",
      " [ 4.95990147e-01 -1.59328162e-01 -8.53585561e-01  2.74682805e-01]]\n",
      "[[ 6.86097978e+02  4.15408334e+01  2.82086743e+02  7.20292706e+02]\n",
      " [-1.50132490e+01  6.92698032e+02  1.76895247e+02 -7.82865846e+01]\n",
      " [ 2.70650235e-02  7.19425032e-02  9.97041504e-01  2.74682805e-01]]\n"
     ]
    }
   ],
   "source": [
    "# 得到P\n",
    "# 合并R，t\n",
    "outArgu1 = np.column_stack((R1,t))\n",
    "outArgu2 = np.column_stack((R2,t))\n",
    "\n",
    "P1 = np.dot(K,outArgu1)\n",
    "P2 = np.dot(K,outArgu2)\n",
    "\n",
    "print(P1)\n",
    "print(P2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "有opencv库内置函数？？算坐标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "help(cv2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后面有2条路：\n",
    "1. Bundle Adjustment\n",
    "2. 多视图"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
