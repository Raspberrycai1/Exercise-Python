2020-9-25

学习openCV 3

# 第18章 相机模型与标定

## 射影几何基础

### 射影变换：

将物理世界中坐标为 (Xi, Yi, Zi) 的一系列**物理点Qi** 映射到**投影平面**上坐标为 (xi, yi) 的点的过程。

### 齐次坐标：

是：给定欧氏平面上的一点(*x*,*y*)，对任意非零实数 Z，三元组(*xZ*,*yZ*,*Z*)即称之为该点的齐次坐标。依据定义，将齐次坐标内的数值乘上同一个非零实数，可得到同一点的另一组齐次坐标。例如，笛卡儿坐标上的点 (1,2) 在齐次坐标中即可标示成 (1,2,1) 或 (2,4,2)。原来的笛卡儿坐标可透过将前两个数值除以第三个数值取回。因此，与笛卡儿坐标不同，一个点可以有无限多个齐次坐标表示法。

齐次坐标把**维数为n**的**投影空间**上的点用(n + 1) 维向量表示 (例如x, y, z 变为x, y, z, w) ，其额外限制是任意两个点的值成比例时即为等价点。

这里，图像平面是一个二维投影空间，因此可以利用一个三维向量 q=(q1,q2,q3) 来表示该平面上的点。由于所有点在投影空间中的比例值相同，因此我们可以通过除以q3得到实际的像素坐标值。

### 相机的内参矩阵：

相机成像装置的中心不在光轴上，因此引入两个新参数$c_x,c_y$，对投影屏幕坐标中心可能的偏移(相对光轴)进行建模。

单个像素在低价成像装置上是矩形而不是正方形，焦距fx实际上是透镜的物理焦距长度与成像装置每个单元尺寸sx的乘积（这样做的意义在于sx的单位是像素/每毫米，而f 的单位是毫米，这意味着fx 的单位是像素)。同样的道理也适用于fy和sy 。请记住，sx和sy以及物理焦距f 均不能在相机标定过程
中直接测量，只有组合量 fx=f \*sx和 fy= f\*sy可以直接计算出来而不必拆除相机去直接测量其部件。

将定义相机的参数(如fx, fy, cx和cy ) 重新排列为一个3 x 3 的矩阵；将物理世界中的点投影到相机上，可用下列简单的形式表示：

$\vec{q} = M \cdot \vec{Q} $
$$
\vec{q}= \begin{bmatrix}x \\ y\\ w \end{bmatrix}\quad
M=\begin {bmatrix} f_x & 0 & c_x \\ 0 & f_y & c_y \\ 0 & 0 & 1 \end{bmatrix} \quad
\vec{Q}=\begin{bmatrix}X \\ Y \\ W \end{bmatrix}\\
$$
将乘数提取出来，可以发现 w=Z，并且是用齐次坐标表示的，可除以w 得到实际像素坐标值

### cv::convertPointsToHomogeneous() 

功能：转换成齐次坐标

需要一个N维点的向量(用一般形式表示) ，并且从该向量中构造出(N + 1)
维点的向量。所有新构造的向量所添加的维度值设置为1 。结果为:$\vec{dst_1}=(src_{i,0}\; src_{i,1}\;... src_{i,N-1}\; 1)$

### cv::convertPointsFromHomogeneous

### Rodrigues变换

在三维空间操作时，通常使用**3x3矩阵**来表示空间中的旋转。因为将向量乘以该矩阵相当于以某种方式旋转向量。缺点是很难理解3 x 3矩阵表示什么样
的旋转。

### 透镜畸变

#### 径向畸变

由透镜的形状造成：在成像装置边缘附近的像素位置产生显著的畸变

#### 切向畸变

由整个相机的组装过程造成：当透镜不完全与图像平面平行的时候会产生切向畸变

#### 5个畸变参数

k1、k2 和 k3 是使用泰勒级数 矫正径向畸变 引入的 系数
p1、p3 是矫正切向畸变引入的参数

畸变向量：5X1矩阵：
$$
\begin{bmatrix} k_1 \ k_2\ p_1\ p_2\ k_3 \end{bmatrix}^T
$$

## 标定

标定相机通常需要做两件事情:第一是纠正畸变的影响，第二是根据获得的图像重构三维场景。

OpenCV 提供了计算内参矩阵和畸变向量的算法

通过 cv::calibrateCamera() 完成标定：

标定方法：**把相机对准一个具有很多独立可标识点的已知结构**。通过从多个视角观察这个结构，我们可以计算拍摄每个图像时相机的（相对）位置和方向以及相机的内部参数。为了提供多个视角，需要旋转和平移物体。

### 旋转矩阵和平移向量

对相机拍摄的一个特定物体的图像，我们可以**用旋转和平移来描述物体相对于相机坐标系统的姿态**，使用旋转矩阵R 和平移向量t 将点物体上的点P 和图像平面上的点P 关联起来。

**旋转**：任何维数的旋转都可以描述为 **坐标向量 乘上 适当尺寸的方阵**：将坐标系统旋转。的角度等同于将目标点绕此坐标原点反方向旋转同样的角度。最终，旋转等同于在一个新的坐标系统中对点的位置引入一个新的描述。

**三维旋转**可以分解成围绕每个轴的二维旋转，其中旋转轴的度量保持不变。如果依次绕x，y，z轴旋转角度 $\psi$,$\phi$,$\theta$, 总的旋转矩阵R是$R_x(\psi)$、$R_y(\phi)$、$R_z(\theta)$ 的乘积：先绕z轴，再绕y轴，再绕x轴，其中
$$
R_x(\psi)=
\begin{bmatrix}
1 & 0 & 0 \\
0 & cos{\psi} & sin{\psi}\\
0 & -sin{\psi} & cos{\psi}
\end{bmatrix} \\

R_y(\phi)=
\begin{bmatrix}
cos{\phi}&0 & -sin{\phi}\\
0 & 1 & 0 \\
sin{\phi}&0 & cos{\phi}
\end{bmatrix} \\

R_z(\theta)=
\begin{bmatrix}
cos{\theta}	&	sin{\theta}	& 0\\
-sin{\theta}&	cos{\phi}	& 0\\
0 			& 	0 			& 1 \\
\end{bmatrix} \\
$$
因此:
$$
R = R_x(\psi)\cdot R_y(\phi) \cdot R_z(\theta)
$$


**矩阵乘法表示二维旋转**：

将点旋转角度$\theta$ (这里绕z轴旋转) 等同于将坐标轴反向旋转$\theta$ ,通过简单的三角函数，我们可以看到旋转如何改变点的坐标。

![image-20200927113310884](C:\Users\MY\AppData\Roaming\Typora\typora-user-images\image-20200927113310884.png)

**平移向量**：是第一个坐标系统的原点到第二个坐标系统的原点的偏移量。因此从以物体为中心的原点的坐标系到以相机中心为原点的坐标系，相应的平移向量为：
$$
\vec{T}=origin_{object}-origin_{camera}
$$
因此可得到一个点在物体（或世界）坐标系中坐标为 $\vec{P_0}$ ，对应相机坐标系中的坐标 $\vec{P_c}$ ：
$$
\vec{P_c} = R \cdot (\vec{P_0}-\vec{T})
$$

### 标定板

棋盘

#### 用cv::findChessboardCorners()找到棋盘角点

如果可以找到并排序图案中的所有角点， cv::findChessboardCorners() 的返回值将被设置为true ，否则为false。

```c++
bool cv::findChessboardCorners(	//Return true if corners were found
    cv::InputArray	image,		//Input chessboard image,8UC1 or 8UC3
    cv::Size		patternSize,//corners per row,and per column
    cv::OutputArray	corners,	//output array of detected corners
    int				flags	= cv::CALIB_CB_ADAPTIVE_THRESH|cv::CALIB_CB_NORMALIZE_IMAGE
)
```

这个函数将包含棋盘的单个图像作为参数，该图像**必须是8 比特图像**。

**patternSize 表示棋盘的每行和每列有多少角点**（例如cv~ :Size(cols ， rows) )。这个值是内角点数

**corners 是记录角点位置的输出矩阵**。用像素坐标表示角点位置的每个值。

**flags 实现一个或多个附加滤波步骤**，以帮助找到棋盘上的角点，可以使用布尔OR 来组合以下任意或所有的参数：

> **cv::CALIB_CB_ADAPTIVE_THRESH**
> cv::findChessboardCorners()的默认方式是根据平均亮度对图像进行阈值化，如果设置此标志，则会使用自适应阈值法
>
> **cv::CALIB_CB_NORMALIZE_IMAGE**
> 如果设置此标志，则在应用阈值化操作之前使用cv::equalizeHist()来归一化图像。
>
> **cv::CALB_CB_FILTER_QUADS**
> 一旦图像阙值化，算法就会尝试从棋盘上的黑色方块的透视图中找出四边形。这是一个近似，因为假设四边形的每个边缘的线是直的，当图像中存在径向畸变时，就会不正确。如果设置了这个标志，就会对这些四边形应用各种附加约束，以防出现错误的四边形。
>
> **cv::CALB_CV_FAST_CHECK**
> 当出现此标志时，则对图像进行快速扫描，以确保图像中存在角点。如果不存在角点，则直接跳过此图像。如果你确定输入数据是"干净的"并且每幅图像中都有棋盘，则此标志就不需要存在。否则，如果在输入中存在没有棋盘的图像，那么使用该标志将节省大量的时间。



#### 棋盘上的亚像素角点和cv::cornerSubPix()

cv::findChessboardCorners() 使用的内部算法仅提供角点的近似位置。因此， cv::cornerSubPix() 由cv::findChessboardCorners() 自动调用，以获得更准确的结果。这在实际中意味着这些位置是相对准确的。但是，如果你希望将它们定位到非常高的精度，则需要在输出上自己调用cv::cornerSubPix() (有效地再次调用它) ，但是需要更严格的终止条件。

#### 使用cv::drawChessboardCorners()绘制棋盘角点

把找到的棋盘角点绘制到图像上（通常是我们第一次计算角点的图像）；这样，我们可以看到投影的角点是否与观察到的角点相匹配。使用这个函数，如果没有找到所有的角点，，则可用的角点将被表示为小的红色圆圈。如果整个图案上的角点都找到，那么角点将被绘制成不同的颜色(每一行都将有自己的颜色) ，并将角点以一定顺序用线连接起来。

```c++
void cv::drawChessboardCorners(
    cv::InptOutput	image,		//Input/output chessboard image,8UC3
    cv::Size		patternSize,//corners per row,and per column
    cv::InputArray	corners,	//corners from findChessboardCorners()
    bool			patternWasFound	//Returned from findChessboardCorners()
);
```

的第一个参数是要绘制的图像。由于角点是用有颜色的圆圈表示的，因此必须为8 位的彩色图像。在大多数情况下，它是你提供给cv: :findChessboardCorners() 的图像的一个副本(但是如果不是三通道图像，则需要转换为三通道图像)。接下来的两个参数patternSize 和corners 与c v : :findChessboardCorners() 中对应的参数一样。最后的参数patternWasFound表示是否整个棋盘图案上的角点都被成功找到，这可以设置为cv::findChessboardCorners() 的返回值。

## 单应性

**平面的单应性**：从一个平面到另一个平面的投影映射，因此<u>二维平面上的点到相机的成像器上的映射</u>就是平面单应性。

将单应性简单表示如下：
$$
\vec{q} = s \cdot H \cdot \vec{Q}
$$
s 是一个任意的比例因子（用于明确指出单应性被定义到该比例因子）。它通常是从H中分解出来的。

变换矩阵H有两个部分：用于定位观察的物体平面的**物理变换**和使用**相机内参矩阵$M$**的射影变换。

物理变换部分：是与观察的图像平面相关的旋转矩阵R和平移矩阵t 的影响之和。因为使用齐次坐标，我们可以将它们组合到如下的矩阵中：
$$
W = \begin{bmatrix} R \quad \vec{t} \end{bmatrix}
$$
所以观察点$\vec{Q}$ 与成像装置上的点 $\vec{q}$ 的映射关系是：
$$
\vec{q}=s \cdot M \cdot W \cdot \vec{Q}
$$
实际上，我们并不关注所有空间的坐标 $\vec{Q}$ ，而只是定义在我们所观察的平面上的坐标 $\vec{Q'}$，因为在物体平面上，Z=0，将W旋转矩阵分解成3个3x1的列向量，其中一个列向量就不需要了
$$
\begin{bmatrix} x \\ y \\ 1 \end{bmatrix} =
s \cdot M \cdot \begin{bmatrix} \vec{r_1}& \vec{r_2} & \vec{r_3} & \vec{t}  \end{bmatrix} \cdot
\begin{bmatrix} X \\ Y \\ 0 \\ 1 \end{bmatrix} =
s \cdot M \cdot \begin{bmatrix} \vec{r_1}& \vec{r_2} & \vec{t}  \end{bmatrix} \cdot \begin{bmatrix} X \\ Y \\ 1 \end{bmatrix}
$$
将平面对象的点映射到成像装置的单应性矩阵H可以描述为$H = s \cdot M \cdot [\vec{r_1} \quad \vec{r_2} \quad \vec{t}]$ ，其中:
$$
\vec{q}=s \cdot H \cdot \vec{Q'}
$$
通过观察可以得出H 是一个3x3的矩阵。

openCV使用上述等式计算单应性矩阵H，它使用**同一物体的多个图像来计算**每个视图的平移和旋转矩阵以及内参矩阵(对于所有视图都是相同的) 。实际上，从多个视图中计算多个单应性矩阵是OpenCV用于求解相机内在参数的方法。

### cv:: findHomography()

**将一系列对应点作为输入，返回最能描述这些对应点的单应性矩阵**。我们至少需要四点来求解H，但如果我们有更多点的话，可以提供更多的点（因为我们会使用大于3x3的棋盘）。使用更多的点是很有用的，因为这样可以减小噪音和其他不确定因素的干扰。

```c++
cv::Mat cv::findHomography(
    cv::InputArray	srcPoints,	//Input array source points(2-d)
    cv::InputArray	dstPoints,	//Input array result points(2-d)
    cv::int			method	=0,	//0,cv::RANSAC, cv::LMEDS,etc
    double			ransacReprojecThreshold = cv::noArray()//use only non-zero pts
);
```

**输入矩阵srcPoints和dstPoints** <u>分别包含原始平面和目标平面中的点</u>。这些都是二维点，因此它们必须是Nx2 或 Nx1的CV_32FC2 的矩阵，或cv::Point2f 的STL vector 对象（或这些的任意组合）。

**method** <u>用于决定计算单应性矩阵所使用的算法</u>。如果使用默认值0，则会考虑所有点，计算结果会使重新投影的误差最小。在这种情况下，**重新投影的误差是H乘以“原始”点与目标点之间的欧氏距离的平方之和**。

## 相机标定

使用cv::calibrateCamera() 计算相机内在参数和畸变参数，以及如何使用这些模型来矫正标定后的相机产生图像中的畸变。

### 棋盘角点个数和参数个数

通过标定要求解的参数：9个，包括4个相机内在参数和5个畸变参数。内在参数控制实际物体与生成的图像之间的线性射影变换。因此，它们与外参矩阵合在一起，告诉我们该物体实际位于何处。

在实践中，为了获得高质量的效果，需要至少10张7x8或更大的棋盘图像(只有在图像之间移动足够次数的棋盘才能获得"丰富的"视图)。

### 标定函数

有了几个图像的角点，就可以调用cv::calibrateCamera()，就可以得到相机内参矩阵，畸变系数，旋转向量和平移向量。

```c++
double cv::calibrateCamera(
    cv::InputArrayOfArrays	objectPoints,	//K vecs (N pts each, object frame)
    cv::lnputArrayOfArrays	imagePoints, // K vecs (N pts each, image frame)
	cv::Size	imageSize, // Size of input images (pixels)
	cv::lnputOutputArray	cameraMatrix, // Resulting 3-bY-3 camera matrix
	cv::lnputOutputArray	distζoeffs, // Vector of 4, 5, or 8 coefficients
	cv::OutputArrayOfArrays	rvecs , // Vector of K rotation vectors
	cv::OutputArrayOfArrays	tvecs, // Vector of K translation vectors
	int flags = 0, // Flags control calibration options
	cv::TermCriteria criteria = cv::TermCriteria(
		cv::TermCriteria::COUNT | cv::TermCriteria::EPS,
		30, // ...after this many iterations
		DBL_EPSILON // ...at this total reprojection error
    )
);
```

* **objectPoints** 是向量的向量，**每个向量**包含特定图像的标定图案上的点的坐标。那些坐标在物体坐标系中，所以可以简单使它们在x维和y维中是整数，而在z 维中为零。

* **imagePoints** 它也是向量的向量，并且包含**每个图像**中找到的每个点的位置。如果使用的是棋盘，贝。每个向量将是相应图像中的角点输出矩阵。

* **imageSize** 只是告诉cv::calibrateCamera()提取imagePoints的点的图像有多大（以像素为单位）

* **cameraMatrix** 包含线性内在参数 3x3矩阵

* **distCoeffs** 畸变系数

* rvecs 向量的向量，像输入点的矩阵，包含每个棋盘的旋转矩阵

* tvecs 平移矩阵

* flags 允许对标定过程进行更精确的控制，以下值可以根据需要与布尔OR运算组合在一起。通常，计算内参矩阵时不需其他信息

  > cv::CALIB_USE_INTRINSIC_GUESS
  >
  > cv::CALIB_FIX_PRINCIPAL_POINT
  >
  > cv::CALIB_FIX

### 仅使用cv::solvePnp() 计算外参数

在某些情况下，我们已经知道了相机的内在参数，因此只需要计算正在观察的对象的位置。一般来说，此工作称为N点透视(Perspective N-Point) 或PnP 问题:

### 只用cv::solvePnPRansac() 计算外参数



## 矫正

纠正畸变的影响：通过输入原始图像和由函数cv::calibrateCamera()得到的畸变系数，生成矫正后的图像。我们既可以只用函数cv: :undistort() 使用该算法一次性完成所需的任务，也可以用一对函数cv::initUndistortRectifyMap() 和cv: :remap() 来更有效地处理此事，这通常适用于视频或者同一相机中获取多个图像的应用中。

### 矫正映射

当进行图像矫正时，我们必须指定输入图像中的每个像素在输出图像中移动到的位置，称为"矫正映射" (或有时为"畸变映射" )。这样的映射有以下儿种表示。

1. 双通道浮点数表示

   NxM图像的重映射由双通道浮点数的NxM矩阵表示。对于阁像中的任意给定元素(下标）（i,j），该元素的值为一对数字（i\*,j\*)，表示输入图像的像素（i,j) 应被重新定位的位置。当然因为(i\*， j\* ) 是浮点数， 表示在目标图像中出现了内插。

2. 双矩阵浮点数表示

3. 定点表示

### 使用cv::convertMaps() 在不同表示方式之间转换矫正映射

### 使用cv::initUndistortRectifyMap() 计算矫正映射

基本过程是首先计算矫正映射，然后将其应用于图像。分开操作的原因是，在大多数实际应用中，你只需要计算一次相机的矫正映射，然后随着相机输入新的图像，你将一次又一次地使用这些映射。函数cv::initUndistortRectifyMap() 从相机标定信息中计算矫正映射:

### 使用cv::remap() 矫正图像

一旦计算了矫正映射，就可以使用cv: : remap ()将它们应用于传入的图像。cv::remap() 函数有两个对应于矫正映射的映射参数，例如由
cv::initUndistortRectifyMap() 计算得到的映射参数。cv: :remap() 接受我们讨论的任何矫正映射格式:双通道浮点型、双矩阵浮点型或定点格式(带或不带插值表索引矩阵)。

### 使用cv::undistort() 进行矫正

在某些情况下，只需要校正一个图像，或者对每一个图像重新计算矫正映射。在这种情况下，可以使用更加简洁的cv: : undistort () ，它可以有效地计算映射并将其应用于单个图像。

### 使用cv::undistortPoints() 进行稀疏矫正

## 与标定结合

例程18-1：查找用户指定尺寸的棋盘，尽可能多获取用户要求的完整图像（即，可以找到所有棋盘角点的图像）以及计算相机内在参数和畸变参数。最后，程序进入显示模式，从而让我们可以看到矫正后的相机图像。

```c++
//读取棋盘的宽度和高度，读取和收集所需的视图数量，并标定相机
# include <opencv2/opencv.hpp>
# include <iostream>
using namespace std;
void help(char *argv[]){
    ...
}
int main(int argc,char* arg[])
{
    int n_boards = 0;	//will be set by input list:arg[]
    float image_sf = 0.5f;
    float delay = 1.f;
    int board_w = 0;
    int board_h = 0;
    
    if(argc < 4||argc>6)
    {
        cout <<"\nERROR:Wrong number of input parameters";
        help(argv);
        return -1;
    }
    board_w = atoi(argv[1]);
    board_h = atoi(argv[2]);
    n_boards = atoi(argv[3]);
    if(argc>4) delay = atof(argv[4]);
    if(argc>5) image_sf=atof(argv[5]);
    int board_n = board_w * board_h;
    cv::Size board_sz = cv::Size(board_w,board_h);
    
    cv::VideoCapture capture(0);
    if(!capture.isOpened())
    {
        cout<<"\nCouldn't open the camera\n";
        help(argv);
        return -1;
    }
    //ALLOCATE STORAGE
    vector<vector<cv::Point2f>> image_points;
    vector<vector<cv::Point3f>> object_points;
    // Capture corner views: loop until we've got n_boards successful
	// captures (all corners on the board are found).
    double last_captured_timestamp = 0;
    cv::Size image_size;
    
    while(image_points.size()<(size_t)n_boards)
    {
        cv::Mat image0,image;
        capture >> image0;
        image_size = image0.size();
        cv::resize(image0,image,cv::Size(),image_sf,image_sf,cv::INTER_LINEAR);
        //Find the board
        vector<cv::Point2f> corners;
        bool found = cv::findChessboardCorners(image,board_sz,corners);
        //Draw it
        drawChessboardCorners(image,board_sz,corners,found);
        //If we got a good board,add it to our data
        double timestamp = (double)clock()/CLOCKS_PER_SEC;
        if(found && timestamp - last_captured_timestamp>1)
        {
            
        }
    }
}
```



# 第19章 投影与三维视觉

在立体视觉中，通过把从不同摄像机同时获取的两个（或更多）图像中的特征，与其他图像中的相关特征进行匹配，并分析特征之间的偏差，产生深度信息。这种方法侧重于将视差效应（三角部分）作为一种计算距离的方法。

## 投影

完成摄像机标定后，可以将物理世界中的点准确地投影图像中的点。这意味着，一旦给定一个摄像机附近的三维物理坐标系的位置，就可以**计算出在外部三维点在成像设备中(即在像素坐标系)出现的位置**。这个转换在OpenCV 例程cv::projectPoints() 中进行了实现:

```c++
void cv::projectPoints(
    cv::InputArray	objectPoints,	//3xN/Nx3 Nc=1，1xN/Nx1 Nc=3，or vector<Point3f>
    cv::InputArray	rvec,		//Rotation vector(see cv::Rodrigues)
    cv::InputArray	tvec,		//Translation vector
    cv::InputArray	cameraMatrix,	//3x3相机本征矩阵
    cv::InputArray	distCoeffs	//4,5,or8 elements vector, or cv::noArray()
    cv::OutputArray	imagePoints,	//2xN/Nx2 Nc=1,1xN/Nx1 Nc=2, or vector<Point2f>
    cv::OutputAray	jacobian = cv::noArray(),//Optional,2N x(10+nDistCoeff)
    double			aspectRatio = 0	//If nonzero,fix fx/fy at this value
);
```

输入位于一些刚体上的欲投影的点，之后通过加入旋转和平移来定义物体坐标系和摄像机坐标系之间的关系。实际上cv::projectPoints()函数在cv::calibrateCamera()中被内部调用，其所有可选参数都可以被cv::calibrateCamera()调用。

第一个参数**objectPoints**，是**需要投影的点序列**，它可以是任何常见的格式：Nx3，3xN，Nx1或1xN 的cv::Vec3f 对象数组，或者仅是一个单纯的旧STL类型向量，其中包含**点的位置**。将这些带入物体自身坐标系，之后可以得到**旋转矢量和平移矢量**，将物体坐标系和摄像机坐标系联系起来。如果情况特殊，直接在摄像机坐标系中计算更为简单，那么可以只设置该坐标系中的objectpoints ，并把旋转矢量和平移矢量内的元素设置为0。

cameraMatrix 和 distCoeffs 内参矩阵和畸变系数

imagePoints 是一个由二维点组成的数组，用于储存计算结果。

jacobian 是可选参数，如果选择改参数，它将被赋予每一个点所在位置旋转矢量和平移矢量的分量，摄像机矩阵的元素，以及畸变系数相对应的偏导数的值。如果不需要计算jacobian (实际上大多数情况下都不需要计算) ，可以将其设置为函数cv: : noAr.ray ( ) ，就不会计算。

aspectRatio 可选参数：只有当函数cv::calibrateCamera() 或者函数cv::stereoCalibrate()宽高比固定时，这个参数用于求导。如果这个参数不是0.0，就调整jacobian中的导数。

## 仿射变换与透视变换

（在11章）

仿射变换可以通过一个矩形产生任何平行四边形；透视变换更加普遍，可以通过一个矩形产生任何梯形。

透视变换与投影是紧密结合的。透视投影将三维物理世界的点沿着一组投影线映射成二维图像平面上的点，这些投影线相交于一点，即投影中心。

* cv::transform() 仿射变换一系列点
* cv::warpAffine() 仿射变换整幅图
* cv::getAffineTransform() 从点计算仿射矩阵
* cv::getRotationMatrix2D() 计算仿射矩阵，获得旋转
* cv::perspectiveTransform() 透视变换一系列点
* cv::warpPerspective() 透视变换整幅图
* cv::getPerspectiveTransform() 填充透视变换矩阵的参数

## 立体成像

双摄像机的立体成像四个步骤：

1. 图像去畸变
2. 标定：调整摄像机之间的角度和距离，输出整帧行对齐的图像（后者意味着两个图像平面是共面的，并且两个成像仪上的对应图像行实际上相对于彼此共线）
3. 匹配：在左右摄像机视图中找到相同特征，输出视差图，视差是指在左右摄像机观察得到的相同特征在x坐标上的插值：xl-xr
4. 重投影：如果摄像机的几何排列已知，那么可以通过三角测量将视差图转化为距离。

### 三角测量

理想情况：完美无畸变、对准、已测量好的系统：两个摄像机的**图像平面彼此完全共面，具有完全平行的光轴**（光轴是从投影中心O发出，通过主点c的一条射线，也称为“主光线”），它们是**已知的距离，并且具有相等的焦距**：fl=fr。同时假设主点cx^left^ 和 cx^right^ 已经被校准为在其相应的**左右图像中有相同的像素坐标**。

此外，假设成像仪是**完全行排列**的，使得一个摄像机的每一个像素行与另一个摄像机中的对应行精确的对齐 (我们称之为"摄像机前向平行排列" ) 。同时假设我们可以在物理世界中找到一点$\vec{p}$，在左右图像上的成像点为$\vec{p_l}$和$\vec{p_r}$，对应的横坐标为$\vec{x_l}$和$\vec{x_r}$。

在这种简化的情况下，我们可以发现**深度与视差成反比**，其中视差被简化定义为。这种情况如图19-5所示，![image-20201005141212647](C:\Users\MY\AppData\Roaming\Typora\typora-user-images\image-20201005141212647.png)

**通过相似三角形容易求出深度Z**。参考示意图，我们得到下式:
$$
\frac{T-(x_l - x_r)}{Z-f} = \frac{T}{Z} \\
\Longrightarrow Z = \frac{f \cdot T}{x_l - x_r}
$$
由于深度于视差成反比，显然，二者之间存在非线性关系。当视差趋近于零时，微小的视差变化会造成很大的深度变化。当视差较大时，微小的视差不会造成深度有太大改变。可以得出结论，立体视觉系统**只有在物体与摄像机距离较近时具才有较高的深度分辨率**，如图19-6所示。![image-20201005141630259](C:\Users\MY\AppData\Roaming\Typora\typora-user-images\image-20201005141630259.png)

OpenCV的二维和三维坐标系（右手坐标系）：左右成像仪的像素原点在图像的左上角![image-20201005141945702](C:\Users\MY\AppData\Roaming\Typora\typora-user-images\image-20201005141945702.png)

## 对极几何

为了解决非前向平行对准的成像平面，通过数学方法找到图像投影和畸变图，将左右图像标定为前向平行排列。

## 本征矩阵E和基本矩阵F

本征矩阵E：包含关于物理空间中两个摄像机的平移和旋转的信息。将左侧摄像机所观察到的点P的物理坐标位置与右侧摄像机所看到的相同的点位置相关联。

基本矩阵F：除了包含E中相同的信息外，还包含两个摄像机的内参数。由于F包含内参数信息，它可以在像素坐标系上将两台摄像机关联。将图像坐标系中一个摄像机的像平面上的点与另一个摄像机的像平面上的点关联。

#### 本征矩阵的数学原理

已知一点$\vec{P}$，我们要推导出在两个成像仪上的观测位置$\vec{p_l}$ 和 $\vec{p_r}$ 之间的关系。

#### 基本矩阵数学原理

### OpenCV获得基本矩阵：

通过提供一些已知的对应关系，以类似前面部分中计算图像单应性的方式来计算F。甚至不需要分别校准摄像机，因为可以直接对F进行处理，其中隐含地包含两个摄像机的基本矩阵：cv::findFundamentalMat()

```C++
cv::Mat cv::findFundamentalMat(
    cv::InputArray	points1,	//
    cv::InputArray	points2,
    int			method = cv::FM_RANSAC,
    double		param1 = 3.0,
    double		param2 = 0.99,
    cv::OutputArray	mask = cv::noArray()
)
```

前两个参数是二维或者三维点的数组，以任何常规方式排列。

第三个参数决定了通过对应点计算基本矩阵的方法，并且可以采用四个值之中的一个。对于每个值，对于point1和point2中所需（允许的）点的数量有特定的约束。

| 方法的值      | 点数 | 算法       |
| ------------- | ---- | ---------- |
| cv::FM_7POINT | N=7  | 7点算法    |
| cv::FM_8POINT | N>=8 | 8点算法    |
| cv::FM_RANSAC | N>=8 | RANSAC算法 |
| cv::FM_LMEDS  | N>=8 | LMeds算法  |

## 计算极线

cv::computerCorrespondEpilines() 根据一幅图像中的点列，计算其在另一幅图像中对应的极线。注意，一副图像中给定的任意点，在另一幅图像中都有不同对应的极线。每条计算的极线以三点（a,b,c）的形式编码，这样一来，极线定义如下：
$$
a \cdot x + b \cdot y +c = 0
$$
为了计算极线，函数需要利用通过函数cv::findFundamentalMat() 得到的基本矩阵

```C++
void cv::computeCorrespondEpilines(
    cv::InputArray	points,	//Input points, Nx1 or 1xN(Nc=2) or vector<Point2f>
    int	whichImage,		//Index of image which contains points('1' or '2')
    cv::InputArray	F,	//Fundamental matrix
    cv::OutputArray	lines	//output vector of lines, encoded as tuples(a,b,c)
);
```

这里的第一个参数points，是二维或三维点的输入数组——它可以为任何常规形式，但是这些点应该为浮点型。

参数whichImage必须是1或2，并标明哪幅图像的点被定义，与函数中的数组points1 和 points2 相关联。

F是由函数cv::findFundamentalMat() 返回的3x3矩阵。

lines 是一个浮点型数组，表示将写入的结果极线。每一条极线都以一个三元素向量$\vec{L}=(a,b,c)$的形式编码，包含极线等式a • x+b • y + c=0 的参数。由于极线等式与参数α， b， c的所有归一化无关，它们被默认归一化，使得 $a^2+b^2 = 1$

## 立体标定

是：**计算空间中两个相机之间几何关系的过程。**

**立体标定依靠查找两个摄像机之间的旋转矩阵R和平移矢量T**，R 和 T 都通过函数cv::stereoCalibrate() 计算，与第18章中看到的函数cv::calibrateCamera() 类似，只不过我们现在有两个摄像机，并且**新函数可以计算(或者利用之前的计算)摄像机的崎变矩阵、本征矩阵和基本矩阵**。

立体校正和单摄像机标定之间另一个主要的区别是，在函数cv::calibrateCamera()中，我们以摄像机和棋盘视图之间的一些列旋转和平移向量结束。而在**函数cv::stereoCamera()中，我们搜寻单个旋转矩阵和平移向量来联系左右相机**。

我们已经说明了如何计算本征矩阵和基本矩阵。接下来的问题是，如何计算左右摄像机的R和$\vec{T}$。我们从对任意给定三维点$\vec{P}$ 的物体坐标系的观察开始，可以**分别对两个摄像机使用单摄像机标定**，将$\vec{P}$ 输入每个摄像机的摄像机坐标系（左右摄像机）：
$$
\vec{P_l} = R_l \cdot \vec{P} + \vec{T_l} \\
\vec{P_r} = R_r \cdot \vec{P} + \vec{T_r}
$$
从图19-10也能清晰看出: 两个相机的视图与 $\vec{P_l} = R^T \cdot (\vec{P_r} - \vec{T})$ 有关，通过这三个等式并且分别求解旋转和平移向量，得到如下简单的关系：
$$
R = R_r \cdot R_l^T \\
\vec{T} = \vec{T_r} - R \cdot \vec{T_l}
$$
给定棋盘角点或类似标定物体的多个联合视图， cv::stereoCalibrate() 使用
cv: :calibrateCamera()来计算每一个摄像机分别的旋转和平移参数。

之后，该例程将这些左右旋转和平移的解代人上述等式中，求解两个摄像机之间的旋转和平移参数。

由于图像噪声和舍入误差，每一对棋盘都会使R和子的值产生微小的差别。cv::stereoCalibrate() 将R和?参数的中间值作为真解的初始近似值并采用鲁棒的Levenberg-Marquardt迭代算法，已找到棋盘角点在两个摄像机视图上的（局部地）最小投影误差，并返回R 和 T 的最终结果。

为了使立体标定的结果更清晰：旋转矩阵被用作到与左摄像机共面的右摄像机上；这样就保证了两个像平面平行但是不是行对准的，行对准要在立体矫正章节里。

#### cv::stereoCalibrate() 立体标定

```C++
double cv::stereoCalibrate(	//Return reprojection error
    cv::InputArrayOfArrays	objectPoints,	//向量的向量：各图像的图案形状
    cv::InputArrayOfArrays	imagePoints1,	//向量的向量：各图像的点（cam1）
    cv::InputArrayOfArrays	imagePoints2,	//各图像的点（cam2）
    cv::InputOutputArray	cameraMatrix1,	//cam1的内参矩阵
    cv::InputOutputArray	distCoeffs1,	//cam1的畸变系数
    cv::InputOutputArray	cameraMatrix2,
    cv::InputOutputArray	disCoeffs2,
    cv::Size				imageSize,		//图像大小
    cv::OutputArray			R,				//相对旋转矩阵
    cv::OutputArray			T,				//相对平移向量
    cv::OutputArray			E,				//本征矩阵
    cv::OutputArray			F,				//基本矩阵
    cv::TermCriteria		criteria = cv::TermCriteria(cv::TermCriteria::COUNT|cv::TermCriteria::EPS,30,1e-6),
    int						flags = cv::CALIB_FIX_INTRINSIC 
);
```

1. objectPoints 是一组点数组。数组顶层中的每一个条目与其中一个校准图像相关联。每个这样的条目本身就是一个包含标定图像（在标定图像本身的坐标系上）上点的位置的数组。。这些点需要为三维点，尽管在一些情况下每一个点位置的z坐标将为零。这与函数cv::calibrateCamera() 的情况完全相同，实际上并不必须使用平面标定对象，但通常这样做最方便。

2. imagePoints1 和 imagePoints2 同样也是数组，同样，数组顶层包含于输入图像相对应的条目的每一个条目包含观测到的标定点的位置：imagePoints1 包含左侧摄像机观察到的点，imagePoints2 包含右侧摄像机观察到的点。与objectPoints 中的点不同， imagePointsl和imagePoints2 中的点是二维点，在图像中它们是像素位置。

   > 如果使用棋盘或圆网格对两个摄像机进行标定，那么imagePoints1 和 imagePoints2就只是相应调用函数cv::findChessboardCorners() 的返回值或另一个角(或圆)的网格查找函数的返回值，分别用于左右摄像机视角。

3. 参数cameraMatrix1 和 cameraMatrix2 都是 3x3 的摄像机矩阵，distCoeffs1 和 distCoeffs2 分别是摄像机1 和摄像机2的四项（或五项或七项）畸变系数向量。记住：在这些矩阵中，前两个径向参数首先出现g 紧接着是两个切向参数，最后是后续的径向参数

4. flags 控制cv::stereoCalibrate()使用摄像机内联函数的方式。

5. imageSize是像素中图像的大小。仅用于细化或计算内参数，或者当flags不等于cv::CALIB_FIX_INTRINSIC 时。

6. R 和 T 项输出参数，在函数返回时被填入代求的（用于联系左右像机的）旋转矩阵和平移向量。

7. E 和 F 是可选的。 如果二者没有被设置为cv: :noArray() ，那么函数cv::stereoCalibrate() 将使用3 x 3 的本征矩阵和基本矩阵进行计算并填入这些数组。

8. termCrit 它将内部优化设置为在一定数量的迭代后终止或者当计算参数小于termCrit 结构中指示的阈值时停止。这个函数的典型参数是：

   cv::TermCriteria(cv::TermCriteria::COUNT | cv::TermCriteria::EPS, 30, 1e-6).

   在cv::TERMCRIT_EPS的情况下，相关联的终止标准的值是由当前参数估计给出的重新投影的误差值。就像cv::calibrateCamera() 一样，算法将对所有可用视图上的所有点的总重新投影误差最小化，但是现在对于两个摄像机， cv::stereoCalibrate() 的返回值就是重新投影误差的最终值。

一旦有了旋转和平移值 (R ， •t ) ， 或者基本矩阵F，我们就可以使用这些结果来标定两幅立体图像，使得极线沿着图像行对准，且扫描线在两个图像上是相同的。尽管R和T 并不决定唯一的立体校正，我们将在下一小节中探讨这些项如何与其他约束一起对图像进行标定。

## 立体矫正

是：**纠正各个图像**的过程，使之它们看起来像是由两个像平面行对准的两个摄像机拍摄。经过矫正，两个摄像机的光轴（或主射线）是平行的（即所谓的相交于无穷远处）。

矫正后（两个像平面精确行对准），最容易计算立体视差。特别的，可靠性和计算效率都通过只搜索一行以与另一图像中的点进行匹配来增强。在包含每个图像的公共像平面进行水平对准的结果是，极点都位于无穷远:即在一幅图像上的投影中心成像与另一个像平面平行。但是，**由于可以选择的前向平行平面的数量是无限的**，我们仍然需要引入一些约束，这些约束基于视图重叠最大化或畸变最小化。

对准两个像平面过程的结果有八项，**每四个分别对应左右摄像机**。对于每个摄像机将得到一个**畸变矢量distCoeffs 、一个旋转矩阵Rrect ( 应用于摄像机)、矫正和未矫正的摄像机矩阵(分别为M rect 和M)** 。通过这些项，利用函数cv::initUndistortRectifyMap()，我们可以创建一个映射，表明我们从原始图像中插入像素的位置，以创建一个新的矫正图像。

有很多算法可以计算矫正项，opencv实现了两个：

1. Hartley 算法：只使用基本矩阵F 产生非标定立体视觉，可以通过单个摄像机记录的运动推导出立体结构，虽然与Bouguet矫正算法相比，将产生更多的 畸变图像。
2. Bouguet 算法：使用两个标定摄像机中的旋转和平移参数。

### 非标定立体矫正：Hartley算法 cv::stereoRectifyUncalibrated()

旨在找到将极点映射到无穷远处的单应矩阵，同时使两幅立体图像之间的计算误差最小化，这可以通过匹配两幅图像之间的对应点实现。

### 已标定的立体矫正：Bouguet 算法 cv::stereoRectify()

### 矫正映射 cv::initUndistortRectifyMap()

一旦有了立体矫正项，我们可以**分别调用cv::initUndistortRectifyMap() 函数来预计算左右摄像机视图的左右矫正查找映射**。与任何图像到图像映射功能一样，前向映射（其中我们仅计算像素从源图像到目标图像的位置）将不会由于浮点目标位置而命中所有目标图像对应的像素位置——目标图像将看起来像瑞士奶酪。所以我们采用**后向工作方式**：对于目标图像中每一整体像素位置，我们查找源图像上的浮点位置，之后利用周围源像素的整型值插值出新的值。这种查找一般使用双线性插值。见11章cv::remap()

矫正过程如图19-12：![image-20201005191004861](C:\Users\MY\AppData\Roaming\Typora\typora-user-images\image-20201005191004861.png)

实际的矫正过程是从c到a 执行（逆映射）。对于在已矫正的图像c中的每一个整数像素，我们在无畸变的图像b中找到它的坐标，然后使用这些查找原始图像中实际的（浮点）坐标。浮点坐标像素值是来自在源图像追踪附近的整数像素位置插值，这个值被用于填充在目标图像中的矫正的像素位置。矫正图像被填充完毕后，通常被裁剪来强调左右图像重叠的区域。

为了左右图像，分别调用一次initUndistortRectifyMap

```C++
void cv::initUndistortRectifyMap(
    cv::InputArray cameraMatrix, //3x3 Camera intrinsics matrix
	cv::InputArray distCoeffs, //5x1 Camera distortion coefficients
	cv::InputArray R, // (Optional) 3x3 rotation matrix
	cv::InputArray newCameraMatrix, // New camera matrix usually
	// from cv::stereoRectify()
	cv::Size size, // Undistorted image size
	int m1type, // Method for encoding result maps
	cv::OutputArray map1, // First output undistortion map
	cv::OutputArray map2 // Second output undistortion map
);
```

如果使用cv::stereoRectify() 标定立体相机，我们可以直接从cv::stereoRectify() 中读出我们的cv::initUndistortRectifyMap()的输入。





## 立体匹配

