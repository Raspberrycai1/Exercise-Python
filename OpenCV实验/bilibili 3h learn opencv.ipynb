{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OpenCV-Python\n",
    "## 1. 安装openCV：\n",
    "1. 以管理员身份运行 command prompt \n",
    "2. `conda install -c conda-forge opencv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图片的读取和显示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# 读取图片\n",
    "img = cv2.imread('lena.jpg')\n",
    "# 图片以矩阵的形式存储\n",
    "# print(img)\n",
    "# print(img.shape) #返回图像大小(512,512,3)\"512x512 3通道\"\n",
    "\n",
    "# 显示图片\n",
    "# cv2.imshow('output',img)\n",
    "# cv2.waitKey(0) # 等待键按下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改变尺寸和裁剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imgResize = cv2.resize(img,(300,300))\n",
    "# cv2.imshow('imgResize',imgResize)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# imgCropped = img[0:300,0:100] #高度取0-300；宽度0-100\n",
    "# cv2.imshow('imgCropped',imgCropped)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 播放视频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\highgui\\src\\window.cpp:352: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-455b415a9190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Video\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m \u001b[1;36m0xFF\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'q'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#按q退出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\highgui\\src\\window.cpp:352: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "# 设置每一帧的延时\n",
    "cap = cv2.VideoCapture(\"Resources/test_video.mp4\")\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"Video\",img)\n",
    "    if cv2.waitKey(1)& 0xFF == ord('q'): #按q退出\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用摄像头"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# use WebCam\n",
    "cap = cv2.VideoCapture(0)#只有1个摄像头\n",
    "cap.set(3,640) #3代表宽度\n",
    "cap.set(4,480) #4代表高度\n",
    "cap.set(10,100) #brightness\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    cv2.imshow(\"Video\",img)\n",
    "    if cv2.waitKey(1)& 0xFF == ord('q'): #按q退出\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图像简单处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "kernel = np.ones((5,5),np.uint8) #全1矩阵\n",
    "\n",
    "imgGray = cv2.cvtColor(img, cv2.COLOR_BGRA2GRAY) #转换成灰度图\n",
    "imgBlur = cv2.GaussianBlur(imgGray,(7,7),0)\n",
    "imgCanny = cv2.Canny(img,100,100)\n",
    "imgDialation = cv2.dilate(imgCanny,kernel,iterations=1) #边沿宽度加宽\n",
    "imgEroded = cv2.erode(imgDialation,kernel,iterations=1) #边沿变细\n",
    "\n",
    "cv2.imshow(\"Gray Image\",imgGray)\n",
    "cv2.imshow(\"Gray Blur\",imgBlur)\n",
    "cv2.imshow(\"Gray Canny\",imgCanny)\n",
    "cv2.imshow(\"Gray Dialation\",imgDialation)\n",
    "cv2.imshow(\"Gray Eroded\",imgEroded)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画图:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((512,512,3),np.uint8) #全0矩阵，0是黑色\n",
    "\n",
    "#img[:]=255,0,0 #所有像素是蓝色\n",
    "#img[200:300,100:300]=255,0,0 # 只有一块区域是蓝色\n",
    "\n",
    "#画直线：\n",
    "cv2.line(img,(0,0),(300,300),(0,255,0),3)#背景图,起点，终点，颜色：绿色，线宽\n",
    "cv2.line(img,(0,0),(img.shape[1],img.shape[0]),(0,255,0),3)#终点坐标取图像的宽度和高度\n",
    "\n",
    "#画长方形：\n",
    "#cv2.rectangle(img,(0,0),(250,350),(0,0,255),cv2.FILLED)#填充\n",
    "\n",
    "#画圆\n",
    "cv2.circle(img,(400,50),30,(255,255,0),5)#圆心，半径30\n",
    "\n",
    "#text （背景图,文本,位置,字体,比例,颜色,线宽）\n",
    "cv2.putText(img,\"OPENCV \",(300,200),cv2.FONT_HERSHEY_COMPLEX,1,(0,150,0),1)\n",
    "\n",
    "cv2.imshow(\"Image\",img)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 展平图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrap Prespective \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"cards.jpg\")\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "width,height = 250,350 # 转换后的图像大小:宽,高\n",
    "points1 = np.float32([[11,225],[59,165],[165,210],[120,280]]) #用画图程序,找到原图角点坐标\n",
    "points2 = np.float32([[0,0],[width,0],[width,height],[0,height]]) #设置对应点的新坐标\n",
    "matrix = cv2.getPerspectiveTransform(points1,points2) #视角转换矩阵\n",
    "imgOutput = cv2.warpPerspective(img,matrix,(width,height)) #扭曲视角\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\",img)\n",
    "cv2.imshow(\"Output\",imgOutput)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining Images 在一个窗口显示多张图片\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "\n",
    "imgHor = np.hstack((img,img)) #水平栈\n",
    "imgVer = np.vstack((img,img)) \n",
    "cv2.imshow(\"Horizontal\",imgHor)\n",
    "cv2.imshow(\"Vertical\",imgVer)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 颜色识别 (只识别出黄色)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-65795e0589ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mlower\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh_min\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_min\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_min\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mupper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mh_max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_max\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mv_max\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgHSV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m#经过调节比对之后，得到各参数：14，69，166，255，157，255,然后改上面的初始值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mimgResult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbitwise_and\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#两图像叠加\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Color Detection \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "# 做一个拖拉条\n",
    "cv2.namedWindow(\"TrackBars\")\n",
    "cv2.resizeWindow(\"TrackBars\",640,240) #窗口大小\n",
    "cv2.createTrackbar(\"Hue Min\",\"TrackBars\",14,179,empty) #色调的最小值\n",
    "cv2.createTrackbar(\"Hue Max\",\"TrackBars\",69,179,empty) #色调的最大值\n",
    "cv2.createTrackbar(\"Saturation Min\",\"TrackBars\",166,255,empty) #饱和度 最小值\n",
    "cv2.createTrackbar(\"Saturation Max\",\"TrackBars\",255,255,empty) #饱和度最大值\n",
    "cv2.createTrackbar(\"Value Min\",\"TrackBars\",157,255,empty) #明度\n",
    "cv2.createTrackbar(\"Value Max\",\"TrackBars\",255,255,empty)\n",
    "\n",
    "while True:\n",
    "    img = cv2.imread(\"labo.jpg\")\n",
    "    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\",\"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Saturation Min\",\"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Saturation Max\",\"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Value Min\",\"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Value Max\",\"TrackBars\")\n",
    "    #print(h_min,h_max,s_min,s_max,v_min,v_max)\n",
    "    lower = np.array([h_min,s_min,v_min])\n",
    "    upper = np.array([h_max,s_max,v_max])\n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "    #经过调节比对之后，得到各参数：14，69，166，255，157，255,然后改上面的初始值\n",
    "    imgResult = cv2.bitwise_and(img,img,mask=mask) #两图像叠加\n",
    "    \n",
    "    cv2.imshow(\"Original\",img)\n",
    "    cv2.imshow(\"HSV\",imgHSV)\n",
    "    cv2.imshow(\"Mask\",mask)\n",
    "    cv2.imshow(\"Result\",imgResult)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 识别图形轮廓\n",
    "[findContours](https://blog.csdn.net/dcrmg/article/details/51987348)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#contours/shape detection 识别图形 数角\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def getContours(img):#contours外形；轮廓\n",
    "    # 检测轮廓:\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    # img单通道图像矩阵，可以是灰度图，但更常用的是二值图像，一般是经过Canny、拉普拉斯等边缘检测算子处理过的二值图像；\n",
    "    # contours是一个双重向量，向量内每个元素保存了一组由连续的Point点构成的点的集合的向量，每一组Point点集就是一个轮廓。  有多少轮廓，向量contours就有多少元素。\n",
    "    # cv2.RETR_EXTERNAL :只检测最外层轮廓，并且保存轮廓上所有点：\n",
    "    # cv2..CHAIN_APPROX_NONE :保存物体边界上所有连续的轮廓点到contours向量内\n",
    "    \n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt) #find area\n",
    "        #print(area) #draw contours\n",
    "        #if area>500: #去除噪音，只要大于500像素的\n",
    "        \n",
    "        # 绘制轮廓\n",
    "        cv2.drawContours(imgContour,cnt,-1,(255,0,0),3) #用蓝色线画出轮廓\n",
    "        peri = cv2.arcLength(cnt,True) #轮廓周长，闭合为true\n",
    "        #print(peri)\n",
    "        approx = cv2.approxPolyDP(cnt,0.02*peri,True)#轮廓拐点\n",
    "        #print(len(approx))\n",
    "        objCor = len(approx)\n",
    "        x,y,w,h = cv2.boundingRect(approx)#矩形边界框\n",
    "        \n",
    "        if objCor ==3:  #拐点个数==3\n",
    "            objectType = \"Tri\"\n",
    "        elif objCor == 4:\n",
    "            aspRatio = w/float(h) #宽/高\n",
    "            if aspRatio > 0.95 and aspRatio <1.05:\n",
    "                objectType = \"Square\"\n",
    "            else:\n",
    "                objectType = \"Rectangle\"\n",
    "        elif objCor > 4: objectType = \"Circle\"\n",
    "        else: objectType = \"None\"\n",
    "        \n",
    "        cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        cv2.putText(imgContour,objectType,\n",
    "                    (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,\n",
    "                    (0,0,0),2)\n",
    "        \n",
    "\n",
    "\n",
    "img = cv2.imread(\"Resources/shapes.png\")\n",
    "imgContour = img.copy() #copy the image\n",
    "\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "imgBlur = cv2.GaussianBlur(imgGray,(7,7),1) #kernel和sigma，sigma越大越模糊\n",
    "imgCanny = cv2.Canny(imgBlur,50,50)\n",
    "getContours(imgCanny)\n",
    "\n",
    "imgBlank = np.zeros_like(img)\n",
    "\n",
    "# cv2.imshow(\"Original\",img)\n",
    "# cv2.imshow(\"Gray\",imgGray)\n",
    "# cv2.imshow(\"Blur\",imgBlur)\n",
    "# cv2.imshow(\"Canny\",imgCanny)\n",
    "# cv2.imshow(\"Blank\",imgBlank)\n",
    "cv2.imshow(\"Contour\",imgContour)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 虚拟笔刷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0be7f155655e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mimgResult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mnewPoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfindColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmyColors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmyColorValues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewPoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnewP\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnewPoints\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-0be7f155655e>\u001b[0m in \u001b[0;36mfindColor\u001b[1;34m(img, myColors, myColorValues)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mupper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minRange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgHSV\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcircle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgResult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmyColorValues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFILLED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-0be7f155655e>\u001b[0m in \u001b[0;36mgetContours\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgetContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m     \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhierarchy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_EXTERNAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_NONE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcnt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontours\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# virtual paint project 1\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "frameWidth = 640\n",
    "frameHeight = 480\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,frameWidth)\n",
    "cap.set(4,frameHeight)\n",
    "cap.set(10,150)\n",
    "\n",
    "myColors = [[5,107,0,19,255,255],#橘黄色\n",
    "            [133,56,0,159,156,255],#purple\n",
    "            [57,76,0,100,255,255]]#green\n",
    "myColorValues = [[51,153,255],   #BGR\n",
    "                 [255,0,255],\n",
    "                 [0,255,0]]\n",
    "           \n",
    "myPoints = [] #[x,y,colorId]\n",
    "\n",
    "\n",
    "def findColor(img,myColors,myColorValues):\n",
    "    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV) #转换到HSV颜色空间\n",
    "    count = 0\n",
    "    newPoints=[]\n",
    "    for color in myColors:\n",
    "        lower = np.array(color[0:3])\n",
    "        upper = np.array(color[3:6])\n",
    "        mask = cv2.inRange(imgHSV,lower,upper)\n",
    "        x,y = getContours(mask)\n",
    "        cv2.circle(imgResult,(x,y),10,myColorValues[count],cv2.FILLED)\n",
    "        if x!=0 and y!=0:\n",
    "            newPoints.append([x,y,count])\n",
    "        count += 1\n",
    "        #cv2.imshow(str(color[0]),mask)\n",
    "    return newPoints\n",
    "        \n",
    "def getContours(img):\n",
    "    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "    x,y,w,h = 0,0,0,0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area>500:\n",
    "            #cv2.drawContours(imgResult, cnt,-1,(255,0,0),3)\n",
    "            peri = cv2.arcLength(cnt,True)\n",
    "            approx = cv2.approxPolyDP(cnt,0.02*peri,True)\n",
    "            x,y,w,h = cv2.boundingRect(approx)\n",
    "    return x+y//2,y\n",
    "\n",
    "def drawOnCanvas(myPoints,myColorValue):\n",
    "    for point in myPoints:\n",
    "        cv2.circle(imgResult,(point[0],point[1]),10,myColorValues[point[2]],cv2.FILLED)\n",
    "\n",
    "    \n",
    "while True:\n",
    "    success,img = cap.read()\n",
    "    imgResult = img.copy()\n",
    "    newPoints = findColor(img,myColors,myColorValues)\n",
    "    if len(newPoints)!=0:\n",
    "        for newP in newPoints:\n",
    "            myPoints.append(newP)\n",
    "            \n",
    "    if len(myPoints)!=0:\n",
    "        drawOnCanvas(myPoints,myColorValues)\n",
    "    \n",
    "    cv2.imshow(\"Result\",imgResult)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detectation\n",
    "# opencv cascades\n",
    "import cv2\n",
    "\n",
    "faceCascade = cv2.CascadeClassifier(\"Resources/haarcascade_frontalface_default.xml\")\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = faceCascade.detectMultiScale(imgGray,1.1,4)\n",
    "\n",
    "for (x,y,w,h) in faces:#create bounding box\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "cv2.imshow(\"Result\",img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document Scanner project 2 文件扫描\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
